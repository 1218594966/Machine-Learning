# å…ƒå©´å¢ƒé¢˜åº“è¯¦è§£

å…ƒå©´é˜¶æ®µé‡åœ¨å¾¡é˜µé©­å…½ï¼šæ„å»ºæ•°æ®é¢„å¤„ç†æµæ°´çº¿ã€é©¾é©­ç›‘ç£/æ— ç›‘ç£ç®—æ³•ã€è¯„ä¼°æ¨¡å‹è¡¨ç°å¹¶å‡†å¤‡éƒ¨ç½²ã€‚ä»¥ä¸‹é€é¢˜è¯¦è§£å¸®åŠ©ä¿®å£«ç†è§£æ¯é¡¹è¯•ç‚¼çš„ç›®æ ‡ã€å…³é”®ä»£ç ä¸å¸¸è§é—®é¢˜ã€‚

## ç„é˜µå¸ƒå±€ Â· æ•°æ®é¢„å¤„ç†

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šä½¿ç”¨ `train_test_split` åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼Œè®¾å®šéšæœºç§å­ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šæ„å»º `ColumnTransformer`ï¼Œä¸ºæ•°å€¼åˆ—åšæ ‡å‡†åŒ–ï¼Œä¸ºç±»åˆ«åˆ—åšç‹¬çƒ­ç¼–ç ã€‚
3. ğŸ”¥ çªç ´ï¼šè¯†åˆ«ç±»åˆ«ä¸å¹³è¡¡å¹¶åº”ç”¨é‡‡æ ·æˆ– class_weight è§£å†³ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šåŸºäºåŸå§‹å­—æ®µæ„é€ è‡ªå®šä¹‰ç‰¹å¾ï¼ˆå¦‚çµçŸ³å¯†åº¦ï¼‰ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šå°†è®­ç»ƒå¥½çš„é¢„å¤„ç†å™¨åºåˆ—åŒ–ä¿å­˜ï¼Œä»¥ä¾¿éƒ¨ç½²é‡ç”¨ã€‚

### é€é¢˜æ‹†è§£
- **é¢˜ 1**ï¼š`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)`ï¼›è§£é‡Š `stratify` å¯ä¿æŒç±»åˆ«æ¯”ä¾‹ã€‚
- **é¢˜ 2**ï¼š```
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
    ]
)
```
è¯´æ˜ `handle_unknown='ignore'` å¯é¿å…é¢„æµ‹é˜¶æ®µå‡ºç°æœªçŸ¥ç±»åˆ«æ—¶æŠ¥é”™ã€‚
- **é¢˜ 3**ï¼šè®¡ç®—ç±»åˆ«åˆ†å¸ƒ `y_train.value_counts(normalize=True)`ï¼›è‹¥æåº¦ä¸å¹³è¡¡ï¼Œå¯å°è¯• `SMOTE`ã€`RandomOverSampler` æˆ–æ¨¡å‹å‚æ•° `class_weight='balanced'`ã€‚
- **é¢˜ 4**ï¼šåœ¨ `ColumnTransformer` å¤–éƒ¨å…ˆæ·»åŠ æ–°åˆ— `df['density'] = df['mana'] / df['weight'].replace(0, np.nan)`ã€‚æ³¨æ„é™¤é›¶å¤„ç†ï¼Œå¹¶è€ƒè™‘å¯¹æ•°å˜æ¢ã€‚
- **é¢˜ 5**ï¼š`joblib.dump(preprocessor, 'preprocess.pkl')`ï¼›åŠ è½½æ—¶ `preprocess = joblib.load('preprocess.pkl')`ã€‚æé†’ä¸æ¨¡å‹ä¸€å¹¶å­˜å‚¨ç‰ˆæœ¬å·ï¼Œç¡®ä¿å…¼å®¹ã€‚

## å¾¡å…½è¦è¯€ Â· ç›‘ç£å­¦ä¹ 

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šè®­ç»ƒçº¿æ€§å›å½’é¢„æµ‹çµè¯ä»·æ ¼ï¼Œæ¯”è¾ƒè®­ç»ƒ/æµ‹è¯• RÂ²ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šä½¿ç”¨é€»è¾‘å›å½’é¢„æµ‹ä¿®å£«æ˜¯å¦é£å‡ï¼Œè°ƒèŠ‚æ­£åˆ™åŒ–å¼ºåº¦ã€‚
3. ğŸ”¥ çªç ´ï¼šè®­ç»ƒå†³ç­–æ ‘å¹¶å¯¼å‡ºå›¾å½¢åŒ–ç»“æ„ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šè®­ç»ƒéšæœºæ£®æ—å¹¶åˆ†æç‰¹å¾é‡è¦æ€§ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šå°è¯•æ¢¯åº¦æå‡æˆ– XGBoostï¼Œå¯¹æ¯”æ€§èƒ½ä¸è®­ç»ƒæ—¶é—´ã€‚

### é€é¢˜æ‹†è§£
- **é¢˜ 1**ï¼š`model = LinearRegression(); model.fit(X_train, y_train)`ï¼›è¾“å‡º `r2_score(y_test, model.predict(X_test))`ï¼Œå¹¶å¯¹æ¯”æ¬ æ‹Ÿåˆ/è¿‡æ‹Ÿåˆè¿¹è±¡ã€‚
- **é¢˜ 2**ï¼š`clf = LogisticRegression(max_iter=1000, C=1.0)`ï¼›é€šè¿‡ç½‘æ ¼æœç´¢ `C`ã€`penalty`ï¼ˆ`l1`/`l2`ï¼‰è§‚å¯Ÿç²¾ç¡®ç‡ä¸å¬å›ç‡å˜åŒ–ã€‚
- **é¢˜ 3**ï¼š`tree = DecisionTreeClassifier(max_depth=5, random_state=42)`ï¼›ä½¿ç”¨ `plot_tree` æˆ– `export_graphviz` å¯è§†åŒ–ã€‚å¼ºè°ƒé™åˆ¶æ·±åº¦é¿å…è¿‡æ‹Ÿåˆã€‚
- **é¢˜ 4**ï¼š`rf = RandomForestClassifier(n_estimators=200, random_state=42)`ï¼›`importance = pd.Series(rf.feature_importances_, index=feature_names).sort_values()` ç»˜åˆ¶æ¡å½¢å›¾è§£é‡Šå…³é”®ç‰¹å¾ã€‚
- **é¢˜ 5**ï¼šå®‰è£… `xgboost` æˆ–ä½¿ç”¨ `GradientBoostingClassifier`ï¼›è®°å½•è®­ç»ƒæ—¶é—´ `time.perf_counter()` ä¸æŒ‡æ ‡å·®å¼‚ï¼Œæé†’åˆç†è®¾ç½® `n_estimators`ã€‚

## å¹»é˜µè¿·è¸ª Â· æ— ç›‘ç£å­¦ä¹ 

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šä½¿ç”¨ KMeans å¯¹çµçŸ³å±æ€§èšç±»ï¼Œè§‚å¯Ÿç°‡ä¸­å¿ƒã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šé‡‡ç”¨ PCA é™ç»´è‡³ 2 ç»´ï¼Œå¹¶ç»˜åˆ¶èšç±»æ•£ç‚¹å›¾ã€‚
3. ğŸ”¥ çªç ´ï¼šè¿›è¡Œå±‚æ¬¡èšç±»å¹¶ç»˜åˆ¶æ ‘çŠ¶å›¾ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šä½¿ç”¨ DBSCAN æ£€æµ‹å¼‚å¸¸çµçŸ³ï¼Œè°ƒæ•´è¶…å‚æ•°ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šè®¡ç®—è½®å»“ç³»æ•°ï¼Œè¯„ä¼°èšç±»æ•ˆæœã€‚

### é€é¢˜æ‹†è§£
- **é¢˜ 1**ï¼š`kmeans = KMeans(n_clusters=3, random_state=42)`ï¼›è®­ç»ƒå `kmeans.cluster_centers_` ç»™å‡ºç°‡ä¸­å¿ƒã€‚ç»˜åˆ¶æ•£ç‚¹å›¾æ ‡æ³¨ç°‡æ ‡ç­¾ã€‚
- **é¢˜ 2**ï¼š`pca = PCA(n_components=2)`ï¼›`X_pca = pca.fit_transform(scaled_X)`ï¼›ä½¿ç”¨ `plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels)`ï¼Œè¯´æ˜æ–¹å·®è´¡çŒ®ç‡ã€‚
- **é¢˜ 3**ï¼š`Z = linkage(scaled_X, method='ward'); dendrogram(Z, truncate_mode='level', p=5)`ï¼›å¼ºè°ƒæ ·æœ¬æ•°é‡å¤šæ—¶éœ€è£å‰ªå›¾åƒã€‚
- **é¢˜ 4**ï¼š`db = DBSCAN(eps=0.3, min_samples=5)`ï¼›`labels = db.fit_predict(scaled_X)`ï¼›`labels == -1` è¡¨ç¤ºå™ªå£°ã€‚å¯ç”¨ `sklearn.neighbors.NearestNeighbors` ä¼°è®¡ `eps`ã€‚
- **é¢˜ 5**ï¼š`from sklearn.metrics import silhouette_score; score = silhouette_score(scaled_X, labels)`ï¼›æŒ‡å¯¼ 0~1 çš„è¯„åˆ†å¦‚ä½•è§£è¯»ï¼Œä½äº 0 è¡¨ç¤ºç°‡é‡å ã€‚

## é˜µæ³•éªŒæ”¶ Â· æ¨¡å‹è¯„ä¼°

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šè¾“å‡º `classification_report`ï¼Œç†è§£å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ä¸ F1ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šç»˜åˆ¶æ··æ·†çŸ©é˜µï¼Œè§£é‡Šå››ä¸ªè±¡é™çš„å«ä¹‰ã€‚
3. ğŸ”¥ çªç ´ï¼šç»˜åˆ¶ ROC æ›²çº¿å¹¶è®¡ç®— AUCã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šç»˜åˆ¶å­¦ä¹ æ›²çº¿ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šæ•°æ®æˆ–æ­£åˆ™åŒ–ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šä½¿ç”¨ `cross_val_score` åš K æŠ˜äº¤å‰éªŒè¯ï¼Œç»Ÿè®¡å‡å€¼ä¸æ–¹å·®ã€‚

### é€é¢˜æ‹†è§£
- **é¢˜ 1**ï¼š`from sklearn.metrics import classification_report; print(classification_report(y_test, y_pred))`ï¼›é€é¡¹è§£é‡Š Precision/Recall/F1 å«ä¹‰ã€‚
- **é¢˜ 2**ï¼š`from sklearn.metrics import ConfusionMatrixDisplay; ConfusionMatrixDisplay.from_predictions(y_test, y_pred)`ï¼›è§£è¯» TP/TN/FP/FN å¯¹ä¸šåŠ¡çš„å½±å“ã€‚
- **é¢˜ 3**ï¼š`fpr, tpr, thresholds = roc_curve(y_test, y_proba)`ï¼›`auc = roc_auc_score(y_test, y_proba)`ï¼›è¯´æ˜é˜ˆå€¼è°ƒæ•´å¦‚ä½•å½±å“å¬å›ç‡ã€‚
- **é¢˜ 4**ï¼š`LearningCurveDisplay.from_estimator(model, X, y, cv=5)`ï¼›è§‚å¯Ÿè®­ç»ƒ/éªŒè¯æ›²çº¿æ˜¯å¦è¶‹äºæ”¶æ•›ï¼Œè¯„ä¼°æ˜¯å¦è¿‡æ‹Ÿåˆã€‚
- **é¢˜ 5**ï¼š`scores = cross_val_score(model, X, y, cv=5)`ï¼›è¾“å‡º `scores.mean()` ä¸ `scores.std()`ã€‚æé†’äº¤å‰éªŒè¯éœ€ä¿æŒæ•°æ®æ³„æ¼å¯æ§ã€‚

## çµé˜µè°ƒä¼˜ Â· Pipeline ä¸éƒ¨ç½²

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šæ„å»ºåŒ…å«é¢„å¤„ç†ä¸æ¨¡å‹çš„ `Pipeline`ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šä½¿ç”¨ `GridSearchCV` å¯¹ Pipeline å‚æ•°è°ƒä¼˜ã€‚
3. ğŸ”¥ çªç ´ï¼šä¿å­˜æœ€ä½³æ¨¡å‹å¹¶é‡æ–°åŠ è½½é¢„æµ‹ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šä½¿ç”¨ FastAPI æš´éœ²é¢„æµ‹æ¥å£ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šç¼–å†™æ‰¹é‡æ¨ç†è„šæœ¬ `make_predictions.py`ã€‚

### é€é¢˜æ‹†è§£
- **é¢˜ 1**ï¼š`pipeline = Pipeline([('prep', preprocessor), ('model', RandomForestClassifier())])`ï¼›å¼ºè°ƒ `fit` ä¼šå…ˆæ‹Ÿåˆé¢„å¤„ç†å†è®­ç»ƒæ¨¡å‹ã€‚
- **é¢˜ 2**ï¼š`param_grid = {'model__n_estimators': [100, 200], 'model__max_depth': [None, 10, 20]}`ï¼›`GridSearchCV(pipeline, param_grid, cv=5)` è‡ªåŠ¨æœç´¢ã€‚`model__` å‰ç¼€æŒ‡å‘ Pipeline å­ç»„ä»¶ã€‚
- **é¢˜ 3**ï¼š`joblib.dump(grid.best_estimator_, 'best_model.joblib')`ï¼›åŠ è½½å `estimator = joblib.load('best_model.joblib')` ç›´æ¥è°ƒç”¨ `predict`ã€‚
- **é¢˜ 4**ï¼šç¼–å†™ FastAPIï¼š```
from fastapi import FastAPI
import joblib
app = FastAPI()
model = joblib.load('best_model.joblib')

@app.post('/predict')
def predict(payload: dict):
    df = pd.DataFrame([payload])
    proba = model.predict_proba(df)[0, 1]
    return {'probability': float(proba)}
```
æé†’å¯åŠ¨ `uvicorn` å¹¶æµ‹è¯•ã€‚
- **é¢˜ 5**ï¼š`python make_predictions.py --input data.csv --output predictions.csv`ã€‚è„šæœ¬æ­¥éª¤ï¼šè¯»å– CSV â†’ `model.predict_proba` â†’ åˆå¹¶åŸå§‹ ID ä¸é¢„æµ‹ç»“æœ â†’ ä¿å­˜ã€‚åŠ å…¥æ—¥å¿—è¯´æ˜å¤„ç†æ•°é‡ã€‚
