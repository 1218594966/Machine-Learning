# åŒ–ç¥å¢ƒé¢˜åº“è¯¦è§£

åŒ–ç¥é˜¶æ®µè¦å°†æ·±åº¦å­¦ä¹ ç‚¼è‡³å…ƒç¥å‡ºçªï¼šç†Ÿæ‚‰ PyTorch å¼ é‡ä¸è‡ªåŠ¨æ±‚å¯¼ã€æ„å»ºä¸è®­ç»ƒæ¨¡å‹ã€æ‹“å±•è§†è§‰/åºåˆ—ä»»åŠ¡ï¼Œå¹¶æŒæ¡è¿ç§»å­¦ä¹ å’Œéƒ¨ç½²ã€‚ä»¥ä¸‹è¯¦è§£æ¯ä¸ªè¯•ç‚¼çš„å…³é”®æ­¥éª¤ä¸æ³¨æ„äº‹é¡¹ã€‚

## éš¾åº¦é˜¶æ¢¯å¯¼èˆª

| éš¾åº¦ | æ ¸å¿ƒå…³é”®è¯ | ä»£è¡¨ç»ƒä¹  |
| --- | --- | --- |
| ğŸŒ± å…¥é—¨ | å¼ é‡åŸºç¡€ | åˆ›å»ºå¼ é‡ã€åˆ‡æ¢è®¾å¤‡ã€æŒæ¡è‡ªåŠ¨æ±‚å¯¼ |
| ğŸŒ¿ è¿›é˜¶ | æ¨¡å‹æ„å»º | è‡ªå®šä¹‰ `nn.Module`ã€æ­å»ºè®­ç»ƒ/éªŒè¯å¾ªç¯ |
| ğŸ”¥ çªç ´ | è§†è§‰ä¸åºåˆ— | æ•°æ®å¢å¼ºã€LSTM/CNNã€Grad-CAM å¯è§†åŒ– |
| ğŸŒŸ åœ†æ»¡ | è¿ç§»å­¦ä¹  | å†»ç»“/è§£å†»ç­–ç•¥ã€æ€§èƒ½å¯¹æ¯”è¡¨ã€å®éªŒè®°å½• |
| ğŸ›¡ï¸ åŒ–ç¥ | éƒ¨ç½²å®ˆæŠ¤ | å¯¼å‡º TorchScript/ONNXã€FastAPI æ¨ç†ã€ç›‘æ§å›æ»š |

## å®éªŒç®¡ç†æç¤º

- **å°æ­¥éªŒè¯**ï¼šå…ˆåœ¨è¿·ä½ æ•°æ®é›†ä¸Šè·‘é€šæµç¨‹ï¼Œç¡®è®¤æŸå¤±ä¸‹é™ã€æŒ‡æ ‡è®¡ç®—æ— è¯¯ï¼Œå†æ‰©å¤§è§„æ¨¡ã€‚
- **è®°å½•é…ç½®**ï¼šæŠŠè¶…å‚æ•°ã€ç¡¬ä»¶ä¿¡æ¯ã€è®­ç»ƒæ—¶é•¿å†™å…¥ YAML/JSON æˆ–å®éªŒæ—¥å¿—ï¼Œæ–¹ä¾¿å¤ç°å®éªŒã€‚
- **è§‚å¯Ÿæ¢¯åº¦**ï¼šå®šæœŸæ£€æŸ¥æ¢¯åº¦èŒƒæ•°ä¸å­¦ä¹ ç‡è°ƒåº¦ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ï¼›å¿…è¦æ—¶ä½¿ç”¨æ¢¯åº¦è£å‰ªã€‚

## å…ƒç¥å‡ç»ƒ Â· PyTorch å…¥é—¨

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šåˆ›å»ºå¼ é‡ã€æŸ¥çœ‹å½¢çŠ¶ã€æ•°æ®ç±»å‹ä»¥åŠæ‰€åœ¨è®¾å¤‡ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šå°† NumPy æ•°ç»„è½¬æ¢ä¸ºå¼ é‡å¹¶éªŒè¯å…±äº«å†…å­˜ã€‚
3. ğŸ”¥ çªç ´ï¼šè®¾ç½®éšæœºç§å­ï¼Œä¿è¯ CPU/GPU çš„ç»“æœå¯å¤ç°ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šç†è§£ `requires_grad`ã€`backward` ä¸æ¢¯åº¦ç´¯ç§¯ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šæ¯”è¾ƒ `torch.no_grad()` ä¸ `detach()` çš„åº”ç”¨åœºæ™¯ã€‚

### é€é¢˜æ‹†è§£

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 1 å…¨è§£

```python
import torch  # â‘  å¼•å…¥ PyTorchï¼Œä»¥ä¾¿éŸ©ç«‹åœ¨çµå…½å±±æ´ä¸­è°ƒåº¦å¼ é‡çµæ°”ã€‚
device = "cuda" if torch.cuda.is_available() else "cpu"  # â‘¡ åˆ¤æ–­å¯ç”¨è®¾å¤‡ï¼Œå‘¼åº”éŸ©ç«‹åœ¨ä¹±æ˜Ÿæµ·æ—¶éšæ—¶åˆ‡æ¢é£å‰‘ä¸éå…‰ã€‚
tensor = torch.rand((2, 3), dtype=torch.float32, device=device)  # â‘¢ ç”Ÿæˆ 2Ã—3 éšæœºå¼ é‡ï¼Œæ¨¡æ‹ŸéŸ©ç«‹å¸çº³çš„å…­ç¼•å¤©åœ°çµæ°”ã€‚
print(tensor.shape)  # â‘£ è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼Œè®©éŸ©ç«‹ç¡®è®¤çµæ°”é˜µåˆ—å°ºå¯¸ã€‚
print(tensor.dtype)  # â‘¤ è¾“å‡ºæ•°æ®ç±»å‹ï¼Œå¯¹åº”çµæ°”çº¯åº¦ã€‚
print(tensor.device)  # â‘¥ è¾“å‡ºå¼ é‡æ‰€åœ¨è®¾å¤‡ï¼Œç¡®ä¿ä¸éŸ©ç«‹çš„æ³•å™¨å¥‘åˆã€‚
tensor_cpu = tensor.cpu()  # â‘¦ è‹¥å½“å‰åœ¨ GPUï¼Œåˆ™è½¬å›å‡¡é—´ï¼ˆCPUï¼‰ï¼Œä»¿ä½›éŸ©ç«‹å›å½’é»„æ«è°·é—­å…³ã€‚
print(tensor_cpu.device)  # â‘§ éªŒè¯è½¬æ¢ç”Ÿæ•ˆã€‚
if torch.cuda.is_available():  # â‘¨ è‹¥éŸ©ç«‹æ‰‹æ¡å™¬çµç«ï¼ˆGPUï¼‰ï¼Œå†æ¼”ç¤ºè¿”å›é£å‡ç•Œï¼ˆCUDAï¼‰ã€‚
    tensor_cuda = tensor_cpu.cuda()
    print(tensor_cuda.device)  # â‘© è¾“å‡º CUDA è®¾å¤‡ä½ç½®ã€‚
```

- **â‘ ** å¯¼å…¥ `torch` åï¼ŒéŸ©ç«‹ä¾¿èƒ½æ“æ§å¼ é‡ä¹‹åŠ›ã€‚
- **â‘¡** åˆ¤æ–­ `cuda` å¯ç”¨æ€§æ—¶ï¼Œè‹¥æœ‰ GPU ä¼šè¿”å› `'cuda'`ï¼Œå¦åˆ™ `'cpu'`ï¼Œå¦‚åŒéŸ©ç«‹éšèº«æºå¸¦çš„é’ç«¹èœ‚äº‘å‰‘ã€‚
- **â‘¢** `torch.rand((2, 3), ...)` ç”Ÿæˆä¸€ä¸ª 2 è¡Œ 3 åˆ—çš„éšæœºå¼ é‡ï¼Œæ•°å€¼å‡åŒ€åˆ†å¸ƒåœ¨ `[0, 1)`ï¼Œè±¡å¾å…­é“çµæ°”æŸ±ã€‚
- **â‘£-â‘¥** ä¾æ¬¡æ‰“å°å½¢çŠ¶ `torch.Size([2, 3])`ã€æ•°æ®ç±»å‹ `torch.float32`ã€è®¾å¤‡å¦‚ `cuda:0` æˆ– `cpu`ã€‚
- **â‘¦-â‘§** `tensor.cpu()` è¿”å›ä¸€ä¸ªä½äº CPU çš„å¼ é‡ï¼Œè¾“å‡º `cpu`ï¼Œå¯¹åº”éŸ©ç«‹çŸ­æš‚å›åˆ°ä¸ƒç„é—¨ã€‚
- **â‘¨-â‘©** è‹¥å­˜åœ¨ GPUï¼Œå†æ¬¡ `.cuda()` ä¼šè¾“å‡º `cuda:0`ï¼Œè±¡å¾éŸ©ç«‹é©¾é©­ç´«çº¹é›·ç«¹é£å‡é«˜ç©ºã€‚

ç¤ºä¾‹è¾“å‡ºï¼ˆå‡è®¾å­˜åœ¨ GPUï¼‰ï¼š

```
torch.Size([2, 3])
torch.float32
cuda:0
cpu
cuda:0
```

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 2 å…¨è§£

```python
import numpy as np  # â‘  å…ˆå¼•å…¥å‡¡ä¿—å­¦å ‚çš„ NumPyã€‚
import torch  # â‘¡ å†æ¬¡å¼•å…¥ PyTorchï¼Œè®©éŸ©ç«‹æ¯”è¾ƒä¸¤ç§çµæ°”å®¹å™¨ã€‚
arr = np.ones((2, 2), dtype=np.float32)  # â‘¢ æ„é€  2Ã—2 çš„çµçŸ³çŸ©é˜µï¼Œåˆå§‹æ¯é¢—çµçŸ³å«é‡ä¸º 1ã€‚
tensor = torch.from_numpy(arr)  # â‘£ å°† NumPy é˜µåˆ—è½¬åŒ–ä¸ºå¼ é‡ï¼Œä¿æŒå…±ç”¨åº•å±‚çµåŠ›è„‰ç»œã€‚
print("åˆå§‹ NumPy:")
print(arr)  # â‘¤ è¾“å‡º NumPy æ•°ç»„ã€‚
print("åˆå§‹ Tensor:")
print(tensor)  # â‘¥ è¾“å‡º PyTorch å¼ é‡ã€‚
arr[0, 0] = 5.0  # â‘¦ éŸ©ç«‹ä»¥ç„å¤©æœæ±çŒæ³¨ç¬¬ä¸€é¢—çµçŸ³ã€‚
print("ä¿®æ”¹å NumPy:")
print(arr)  # â‘§ NumPy è§†å›¾æ›´æ–°ã€‚
print("åŒæ­¥çš„ Tensor:")
print(tensor)  # â‘¨ PyTorch å¼ é‡åŒæ­¥å˜åŒ–ï¼Œä½“ç°åŒæºã€‚
detached = torch.tensor(arr.copy())  # â‘© è‹¥éŸ©ç«‹æƒ³å°å­˜å‰¯æœ¬ï¼Œå¯æ˜¾å¼å¤åˆ¶åå†å»ºå¼ é‡ã€‚
```

- **â‘ -â‘¡** åˆ†åˆ«å¯¼å…¥ NumPy ä¸ PyTorchï¼Œå‡†å¤‡çµçŸ³ï¼ˆæ•°ç»„ï¼‰ä¸æ³•é˜µï¼ˆå¼ é‡ï¼‰ã€‚
- **â‘¢** `np.ones((2, 2))` åˆ›å»ºå…¨ 1 é˜µåˆ—ï¼Œè¡¨ç¤ºå››é¢—çµçŸ³åˆå§‹çµæ°”ç›¸ç­‰ã€‚
- **â‘£** `torch.from_numpy` ä¼šå…±äº«å†…å­˜ï¼ŒçŠ¹å¦‚éŸ©ç«‹ä»¥ã€Šé’å…ƒå‰‘è¯€ã€‹è¿æ¥çµçŸ³è„‰ç»œã€‚
- **â‘¤-â‘¥** æ‰“å°å¯è§ä¸¤è€…å‡ä¸º `[[1. 1.]
 [1. 1.]]`ã€‚
- **â‘¦-â‘¨** å½“ NumPy é˜µåˆ—ä¸­æŸå…ƒç´ æ›´æ–°ä¸º `5.0` æ—¶ï¼Œå¼ é‡åŒæ­¥æ˜¾ç¤º `5.0`ï¼Œä»¿ä½›éŸ©ç«‹åœ¨ç´«çµå²›å°†çµæ°”æ³¨å…¥åŒä¸€æ³•é˜µã€‚
- **â‘©** è‹¥ä½¿ç”¨ `torch.tensor(arr.copy())`ï¼Œåˆ™å¼ é‡ä¸åŸæ•°ç»„äº’ä¸å½±å“ï¼Œç›¸å½“äºéŸ©ç«‹åœ¨å¤©å—å¦èµ·ä¸€ç‚‰ä¸¹è¯ã€‚

ç¤ºä¾‹è¾“å‡ºï¼š

```
åˆå§‹ NumPy:
[[1. 1.]
 [1. 1.]]
åˆå§‹ Tensor:
tensor([[1., 1.],
        [1., 1.]])
ä¿®æ”¹å NumPy:
[[5. 1.]
 [1. 1.]]
åŒæ­¥çš„ Tensor:
tensor([[5., 1.],
        [1., 1.]])
```

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 3 å…¨è§£

```python
import random  # â‘  å¼•å…¥å‡¡ä¿—éª°å­ï¼Œç”¨äºæ§åˆ¶éŸ©ç«‹é—­å…³æ—¶çš„æœºç¼˜ã€‚
import numpy as np  # â‘¡ å¯¼å…¥ NumPyï¼Œç¡®ä¿æ´åºœå†…é˜µæ³•ä¸€è‡´ã€‚
import torch  # â‘¢ å¯¼å…¥ PyTorchï¼Œç»Ÿä¸€éšæœºç§å­ã€‚
seed = 1640  # â‘£ è®¾å®šéŸ©ç«‹åœ¨å¤ªå—å°ä¸–ç•Œçš„çºªå¹´ä½œä¸ºéšæœºç§å­ã€‚
random.seed(seed)  # â‘¤ å›ºå®š Python æ ‡å‡†åº“éšæœºæ€§ã€‚
np.random.seed(seed)  # â‘¥ å›ºå®š NumPyã€‚
torch.manual_seed(seed)  # â‘¦ å›ºå®š CPU ä¸Šçš„å¼ é‡éšæœºæ•°ã€‚
if torch.cuda.is_available():  # â‘§ è‹¥éŸ©ç«‹æºå¸¦å™¬é‡‘è™«ï¼ˆGPUï¼‰ï¼Œéœ€è¿›ä¸€æ­¥å›ºå®š CUDAã€‚
    torch.cuda.manual_seed_all(seed)
print(random.random())  # â‘¨ è¾“å‡ºä¸€ä¸ªä¼ªéšæœºæ•°ï¼ŒéŸ©ç«‹é¢„æµ‹çµå…½å‡ºä¸–æ¦‚ç‡ã€‚
print(np.random.rand(2))  # â‘© è¾“å‡º NumPy éšæœºæ•°ç»„ã€‚
print(torch.rand(2))  # â‘ª è¾“å‡º PyTorch éšæœºå¼ é‡ã€‚
```

- **â‘ -â‘¢** åˆ†åˆ«å¯¼å…¥ `random`ã€`numpy`ã€`torch`ï¼Œå¯¹åº”éŸ©ç«‹è°ƒåº¦çš„ä¸‰ç±»æ³•é˜µã€‚
- **â‘£** é€‰å®šå›ºå®šå€¼ `1640`ï¼Œå¯æ›¿æ¢ä¸ºä»»æ„æ•´æ•°ã€‚
- **â‘¤-â‘¦** ä¾æ¬¡è®¾ç§å­ï¼Œç¡®ä¿å¤šæ¬¡è¿è¡Œå¾—åˆ°ç›¸åŒç»“æœï¼ŒçŠ¹å¦‚éŸ©ç«‹åœ¨åŒ–ç¥æˆ˜åœºå¸ƒä¸‹å¯é‡å¤çš„å¹»é˜µã€‚
- **â‘§** å¯¹ GPU è°ƒç”¨ `manual_seed_all`ï¼Œé˜²æ­¢å¤šå¼ æ˜¾å¡ç»“æœä¸ä¸€è‡´ã€‚
- **â‘¨-â‘ª** æ‰“å°å‡ºçš„éšæœºå€¼åœ¨æ¯æ¬¡è¿è¡Œä¸­ä¿æŒç¨³å®šï¼Œç¤ºä¾‹ï¼š

```
0.7208888851403657
[0.93871914 0.81585354]
tensor([0.0250, 0.3015])
```

éŸ©ç«‹å¯æ®æ­¤éªŒè¯é—­å…³å‰åçš„çµæ°”æ³¢åŠ¨å§‹ç»ˆä¸€è‡´ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 4 å…¨è§£

```python
import torch  # â‘  å†æ¬¡å¬å”¤ PyTorch çµé˜µã€‚
x = torch.tensor([2.0], requires_grad=True)  # â‘¡ å®šä¹‰æ ‡é‡å¼ é‡ xï¼Œå¼€å¯æ¢¯åº¦è¿½è¸ªï¼Œå¦‚éŸ©ç«‹æ³¨è§†é‡‘é˜™ç‰ä¹¦ã€‚
y = x ** 2  # â‘¢ ä»¤ y = xÂ²ï¼Œæ¨¡æ‹ŸåŠŸæ³•è¿è½¬å¸¦æ¥çš„çµåŠ›æå‡ã€‚
print(y)  # â‘£ è¾“å‡ºå½“å‰çš„ yã€‚
y.backward()  # â‘¤ åå‘ä¼ æ’­ï¼Œç›¸å½“äºéŸ©ç«‹é€†æ¨åŠŸæ³•è„‰ç»œã€‚
print(x.grad)  # â‘¥ æŸ¥çœ‹æ¢¯åº¦ï¼Œå³ d(xÂ²)/dx = 2xã€‚
x.grad.zero_()  # â‘¦ å°†æ¢¯åº¦æ¸…é›¶ï¼Œå‡†å¤‡ä¸‹ä¸€è½®æ¼”ç»ƒã€‚
z = x ** 3  # â‘§ æ›´æ¢åŠŸæ³•ä¸º xÂ³ã€‚
z.backward()  # â‘¨ å†æ¬¡å›ä¼ ã€‚
print(x.grad)  # â‘© æŸ¥çœ‹æ–°çš„æ¢¯åº¦ 3xÂ²ã€‚
```

- **â‘ -â‘¡** åˆ›å»º `x` æ—¶è®¾ç½® `requires_grad=True`ï¼Œè¡¨ç¤ºæ­¤çµåŠ›èŠ‚ç‚¹éœ€è®°å½•æ¢¯åº¦ã€‚
- **â‘¢-â‘£** è®¡ç®— `y = x ** 2`ï¼Œè¾“å‡º `tensor([4.], grad_fn=<PowBackward0>)`ã€‚
- **â‘¤-â‘¥** `y.backward()` åï¼Œ`x.grad` ä¸º `tensor([4.])`ï¼Œå› ä¸º `2 * 2 = 4`ã€‚
- **â‘¦** `zero_()` å°†æ¢¯åº¦åŸåœ°æ¸…é›¶ï¼Œé˜²æ­¢ç´¯ç§¯ï¼Œå¦‚åŒéŸ©ç«‹åœ¨è™šå¤©é¼å‰é‡ç½®çµåŠ›ã€‚
- **â‘§-â‘©** å†æ¬¡è®¡ç®— `z = x ** 3`ï¼Œå›ä¼ åæ¢¯åº¦ä¸º `tensor([12.])`ï¼Œå¯¹åº” `3 * 2Â² = 12`ã€‚

ç¤ºä¾‹è¾“å‡ºï¼š

```
tensor([4.], grad_fn=<PowBackward0>)
tensor([4.])
tensor([12.])
```

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 5 å…¨è§£

```python
import torch  # â‘  å¼•å…¥ PyTorchã€‚
x = torch.tensor([3.0], requires_grad=True)  # â‘¡ å‡†å¤‡å«æ¢¯åº¦çš„çµåŠ›èŠ‚ç‚¹ã€‚
with torch.no_grad():  # â‘¢ åœ¨æ— æ¢¯åº¦è¯­å¢ƒä¸­ï¼ŒéŸ©ç«‹ä»¿ä½›æ–½å±•ã€Šå¤§åºšå‰‘è¯€ã€‹ä¸­çš„éšåŒ¿ç¯‡ï¼Œå±è”½çµæ°”æ³¢åŠ¨ã€‚
    y = x * 2  # â‘£ è®¡ç®— y = 6ï¼Œæ­¤æ—¶ä¸ä¼šè®°å½•æ¢¯åº¦ã€‚
print(y)  # â‘¤ è¾“å‡ºå¼ é‡ï¼Œæ˜¾ç¤ºæ—  grad_fnã€‚
z = x.detach()  # â‘¥ ä½¿ç”¨ detach å¤åˆ¶è§†å›¾ï¼Œä»å…±äº«å†…å­˜ä½†ä¸è¿½è¸ªæ¢¯åº¦ã€‚
print(z)  # â‘¦ è¾“å‡ºå¼ é‡ï¼Œdevice ä¸å€¼ä¸ x ç›¸åŒã€‚
loss = (x ** 2).sum()  # â‘§ å®šä¹‰å¯å›ä¼ çš„æŸå¤±ã€‚
loss.backward()  # â‘¨ å›ä¼ å x.grad å¾—åˆ° 6ã€‚
print(x.grad.detach().cpu().item())  # â‘© é€šè¿‡ detach()+cpu()+item() æå–çº¯æ•°å€¼ä¾›éŸ©ç«‹è®°å½•ã€‚
```

- **â‘ -â‘¡** åˆ›å»ºå«æ¢¯åº¦çš„å˜é‡ã€‚
- **â‘¢-â‘£** è¿›å…¥ `torch.no_grad()` åçš„è¿ç®—ä¸ä¼šè¢«è®¡ç®—å›¾è®°å½•ï¼Œæ‰“å° `tensor([6.])`ï¼Œæ—  `grad_fn`ã€‚
- **â‘¥-â‘¦** `detach()` è¿”å›ä¸ `x` å…±äº«å­˜å‚¨çš„å¼ é‡ï¼›è‹¥åç»­ä¿®æ”¹ `x`ï¼Œ`z` åŒæ­¥ã€‚
- **â‘§-â‘¨** è®¡ç®— `loss = x ** 2` å¹¶å›ä¼ ï¼Œ`x.grad` å˜ä¸º `tensor([6.])`ã€‚
- **â‘©** ä½¿ç”¨ `detach()` é˜²æ­¢æ¢¯åº¦ç»§ç»­å‚ä¸å›¾è®¡ç®—ï¼Œ`cpu()` ä¾¿äºåœ¨æ—  GPU ç¯å¢ƒè¾“å‡ºï¼Œ`item()` è½¬æ¢ä¸º Python æµ®ç‚¹æ•°ã€‚

ç¤ºä¾‹è¾“å‡ºï¼š

```
tensor([6.])
tensor([3.])
6.0
```

## æ³•èº«å¡‘é€  Â· æ¨¡å‹æ„å»º

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šè‡ªå®šä¹‰ `Net(nn.Module)` å¹¶å®ç° `forward` å‰å‘é€»è¾‘ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šä½¿ç”¨ `torchsummary` æˆ– `torchinfo` æŸ¥çœ‹å‚æ•°é‡ã€‚
3. ğŸ”¥ çªç ´ï¼šç¼–å†™æ ‡å‡†è®­ç»ƒ/éªŒè¯å¾ªç¯ï¼ŒåŒ…å«æ¢¯åº¦æ¸…é›¶ä¸åå‘ä¼ æ’­ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šå¼•å…¥å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œå¦‚ `StepLR` æˆ– `ReduceLROnPlateau`ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šå°†è®­ç»ƒæŒ‡æ ‡å†™å…¥ TensorBoard ä¾¿äºç›‘æ§ã€‚

### é€é¢˜æ‹†è§£

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 1 å…¨è§£

```python
import torch
import torch.nn as nn  # â‘  å¼•å…¥ç¥è¯†æ„ç­‘æ¨¡å—ã€‚

class Net(nn.Module):  # â‘¡ å®šä¹‰æ¨¡å‹ï¼Œå¦‚éŸ©ç«‹ç‚¼åˆ¶çš„é’å…ƒå‰‘é˜µã€‚
    def __init__(self):
        super().__init__()  # â‘¢ åˆå§‹åŒ–çˆ¶ç±»ï¼Œç¡®ä¿å†…åŠŸå¿ƒæ³•ç»§æ‰¿ã€‚
        self.flatten = nn.Flatten()  # â‘£ å°† 28Ã—28 çµçº¹æ‘Šå¹³æˆ 784 é•¿åº¦ã€‚
        self.fc = nn.Linear(784, 10)  # â‘¤ å…¨è¿æ¥å±‚ï¼Œè¾“å‡ºåç§çµå™¨ç±»åˆ«ã€‚

    def forward(self, x):
        x = self.flatten(x)  # â‘¥ å±•å¹³è¾“å…¥ï¼Œä»¿ä½›éŸ©ç«‹å°†é“¶æœˆçš„å¹»åŒ–æ‹†è§£ä¸ºå•çº¿æ¡ã€‚
        logits = self.fc(x)  # â‘¦ çº¿æ€§æ˜ å°„ï¼Œå¾—åˆ°å„ç±»åˆ«çš„çµæ°”å€¼ã€‚
        return logits  # â‘§ è¿”å› logitsï¼Œä¾›åç»­æŸå¤±è®¡ç®—ã€‚

model = Net()  # â‘¨ å®ä¾‹åŒ–æ¨¡å‹ï¼Œå¦‚åŒéŸ©ç«‹åœ¨è™šå¤©é¼å†…ç‚¼æˆæ³•å™¨ã€‚
sample = torch.randn(16, 1, 28, 28)  # â‘© ç”Ÿæˆ 16 å¼ æ‰‹å†™ç¬¦æ–‡ã€‚
output = model(sample)  # â‘ª å‰å‘ä¼ æ’­ã€‚
print(output.shape)  # â‘« è¾“å‡ºå½¢çŠ¶ï¼ŒéªŒè¯ä¸º [16, 10]ã€‚
```

- è¿è¡Œåè¾“å‡º `torch.Size([16, 10])`ï¼Œç¡®è®¤æ‰¹é‡å¤§å°ä¸ç±»åˆ«ç»´åº¦æ­£ç¡®ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 2 å…¨è§£

```python
from torchinfo import summary  # â‘  å¼•å…¥ torchinfoï¼Œä»¿ä½›éŸ©ç«‹æ‰‹æŒå¤©æœºç¬¦å·æ´å¯Ÿæ³•å™¨ç»“æ„ã€‚
model = Net()  # â‘¡ æ²¿ç”¨ä¸Šé¢˜æ¨¡å‹ã€‚
report = summary(model, input_size=(64, 1, 28, 28))  # â‘¢ ç”Ÿæˆæ‘˜è¦ï¼Œæ‰¹æ¬¡ 64ã€‚
print(report)  # â‘£ æ‰“å°è¯¦ç»†å‚æ•°ã€‚
```

- è¾“å‡ºä¼šåˆ—å‡ºæ¯å±‚å½¢çŠ¶ä¸å‚æ•°æ•°é‡ï¼Œä¾‹å¦‚ `Linear` å±‚å‚æ•°ä¸º 7,850ï¼Œå¸®åŠ©éŸ©ç«‹æ£€è§†åŠŸæ³•ç»“æ„ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 3 å…¨è§£

```python
for epoch in range(1, epochs + 1):  # â‘  å¤–å±‚å¾ªç¯éå†è½®æ¬¡ï¼Œç›¸å½“äºéŸ©ç«‹é—­å…³å¤šæ¬¡å†²å‡»ç“¶é¢ˆã€‚
    model.train()  # â‘¡ åˆ‡æ¢è®­ç»ƒæ¨¡å¼ï¼Œæ¿€æ´»è¯¸å¦‚ Dropout çš„é˜µæ³•ã€‚
    for batch_idx, (features, labels) in enumerate(train_loader, start=1):  # â‘¢ éå†æ‰¹æ¬¡ï¼Œè®°å½•ç´¢å¼•ã€‚
        optimizer.zero_grad()  # â‘£ æ¸…ç†æ—§æ¢¯åº¦ï¼ŒçŠ¹å¦‚éŸ©ç«‹æ¯æ¬¡è¿åŠŸå‰å…ˆå½’å…ƒã€‚
        preds = model(features)  # â‘¤ å‰å‘ä¼ æ’­ï¼Œè·å–é¢„æµ‹çµå‹ã€‚
        loss = criterion(preds, labels)  # â‘¥ è®¡ç®—æŸå¤±ï¼Œè¯„ä¼°åå·®ã€‚
        loss.backward()  # â‘¦ åå‘ä¼ æ’­ï¼Œè¿½è¸ªçµåŠ›æµå‘ã€‚
        optimizer.step()  # â‘§ æ›´æ–°å‚æ•°ï¼ŒéŸ©ç«‹è°ƒæ•´åŠŸæ³•è·¯çº¿ã€‚
        if batch_idx % 50 == 0:
            print(f"ç¬¬{epoch}è½®-ç¬¬{batch_idx}æ‰¹ï¼Œè®­ç»ƒæŸå¤±={loss.item():.4f}")  # â‘¨ è¾“å‡ºé˜¶æ®µæ€§æˆ˜æŠ¥ã€‚
    model.eval()  # â‘© åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼ã€‚
    with torch.no_grad():  # â‘ª ç¦ç”¨æ¢¯åº¦ï¼Œé¿å…çµåŠ›æ³¢åŠ¨å¹²æ‰°éªŒè¯ã€‚
        val_loss = 0.0
        for features, labels in val_loader:  # â‘« éå†éªŒè¯é›†ã€‚
            preds = model(features)
            val_loss += criterion(preds, labels).item()
    val_loss /= len(val_loader)  # â‘¬ å¹³å‡åŒ–éªŒè¯æŸå¤±ã€‚
    print(f"ç¬¬{epoch}è½®éªŒè¯æŸå¤±={val_loss:.4f}")  # â‘­ æŠ¥å‘Šæˆæœï¼Œå¦‚åŒéŸ©ç«‹ä¸å—å®«å©‰äº’é€šå¯†ä¿¡ã€‚
```

- ç¤ºä¾‹è¾“å‡ºï¼š`ç¬¬1è½®-ç¬¬50æ‰¹ï¼Œè®­ç»ƒæŸå¤±=0.9451`ã€`ç¬¬1è½®éªŒè¯æŸå¤±=0.8123`ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 4 å…¨è§£

```python
from torch.optim.lr_scheduler import StepLR  # â‘  å¼•å…¥å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # â‘¡ æ¯ 5 è½®è¡°å‡ä¸€æ¬¡ï¼Œå¦‚éŸ©ç«‹é€æ­¥æ”¶æŸçµåŠ›ã€‚
for epoch in range(1, epochs + 1):
    train_one_epoch()
    validate()
    scheduler.step()  # â‘¢ åœ¨æ¯è½®ç»“æŸåè°ƒæ•´å­¦ä¹ ç‡ã€‚
    print(f"ç¬¬{epoch}è½®å­¦ä¹ ç‡={scheduler.get_last_lr()[0]:.6f}")  # â‘£ è¾“å‡ºå½“å‰å­¦ä¹ ç‡ã€‚
```

- è¾“å‡ºç¤ºä¾‹ï¼š`ç¬¬1è½®å­¦ä¹ ç‡=0.010000`ã€`ç¬¬5è½®å­¦ä¹ ç‡=0.001000`ï¼Œå¸®åŠ©éŸ©ç«‹æŒæ¡çµåŠ›èŠ‚å¥ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 5 å…¨è§£

```python
from torch.utils.tensorboard import SummaryWriter  # â‘  å¼•å…¥æ—¥å¿—æ³•é˜µã€‚
writer = SummaryWriter(log_dir="runs/hanli-apotheosis")  # â‘¡ æŒ‡å®šæ—¥å¿—ç›®å½•ã€‚
global_step = 0
for epoch in range(1, epochs + 1):
    for features, labels in train_loader:
        optimizer.zero_grad()
        preds = model(features)
        loss = criterion(preds, labels)
        loss.backward()
        optimizer.step()
        writer.add_scalar("loss/train", loss.item(), global_step)  # â‘¢ è®°å½•è®­ç»ƒæŸå¤±ã€‚
        global_step += 1
    writer.add_scalar("lr", scheduler.get_last_lr()[0], epoch)  # â‘£ æ¯è½®è®°å½•å­¦ä¹ ç‡ã€‚
writer.close()  # â‘¤ å…³é—­å†™å…¥å™¨ï¼Œå¦‚åŒéŸ©ç«‹åˆä¸Šç‚¼ä¸¹æ—¥å¿—ã€‚
print("è¿è¡Œ tensorboard --logdir runs/hanli-apotheosis ä»¥æŸ¥çœ‹ä¿®ç‚¼æ›²çº¿")  # â‘¥ æç¤ºæŸ¥çœ‹æ–¹å¼ã€‚
```

- æ‰“å¼€ TensorBoard åèƒ½è§‚å¯ŸæŸå¤±ä¸å­¦ä¹ ç‡æ›²çº¿ï¼ŒéŸ©ç«‹å³å¯æ´å¯Ÿä¿®ç‚¼èµ°åŠ¿ã€‚

## çµè¯†æ‰©å±• Â· è®¡ç®—æœºè§†è§‰ä¸åºåˆ—

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šä½¿ç”¨ `torchvision.transforms` å¯¹å›¾åƒè¿›è¡Œæ•°æ®å¢å¼ºã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šæ„å»ºç®€å•çš„ LSTM æ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚
3. ğŸ”¥ çªç ´ï¼šå®ç°è‡ªå®šä¹‰ `Dataset`/`DataLoader` ç”¨äºéæ ‡å‡†æ•°æ®ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šè¿ç”¨ Grad-CAM å¯è§†åŒ–æ¨¡å‹å…³æ³¨åŒºåŸŸã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šå¯¹æ¯”ä¸åŒæ‰¹å¤§å°å¯¹è®­ç»ƒé€Ÿåº¦ä¸ç¨³å®šæ€§çš„å½±å“ã€‚

### é€é¢˜æ‹†è§£

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 1 å…¨è§£

```python
from torchvision import transforms  # â‘  å¼•å…¥å›¾åƒç‚¼ä¸¹ç§˜æœ¯ã€‚
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),  # â‘¡ ç»Ÿä¸€å°ºå¯¸ï¼ŒçŠ¹å¦‚éŸ©ç«‹å°†çµå…½ç¼©æ”¾å…¥çµå…½è¢‹ã€‚
    transforms.RandomHorizontalFlip(p=0.5),  # â‘¢ éšæœºæ°´å¹³ç¿»è½¬ï¼Œæ¨¡æ‹Ÿå¹»é˜µé•œåƒã€‚
    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # â‘£ å¾®è°ƒäº®åº¦ä¸å¯¹æ¯”åº¦ï¼Œå¦‚åŒæ´’ä¸‹é’ç«¹èœ‚äº‘å‰‘å…‰ã€‚
    transforms.ToTensor(),  # â‘¤ è½¬ä¸ºå¼ é‡ã€‚
])
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),  # â‘¥ éªŒè¯é›†ä»…åšå°ºåº¦ç»Ÿä¸€ã€‚
    transforms.ToTensor(),
])
```

- è®­ç»ƒé›†é€šè¿‡éšæœºæ‰°åŠ¨æå‡æ¨¡å‹é²æ£’æ€§ï¼ŒéªŒè¯é›†ä¿æŒç¨³å®šï¼Œæ–¹ä¾¿éŸ©ç«‹è¯„ä¼°çœŸå®æˆ˜åŠ›ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 2 å…¨è§£

```python
import torch
import torch.nn as nn

class SpellClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)  # â‘  å°†æ³•è¯€ç¬¦æ–‡æ˜ å°„ä¸ºå‘é‡ã€‚
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)  # â‘¡ è®¾å®š batch_first æ–¹ä¾¿å¤„ç†ã€‚
        self.classifier = nn.Linear(hidden_dim, num_classes)  # â‘¢ è¾“å‡ºæ³•è¯€ç±»åˆ«ã€‚

    def forward(self, inputs, lengths):
        embedded = self.embedding(inputs)  # â‘£ åµŒå…¥å±‚è¾“å‡ºã€‚
        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)  # â‘¤ æ‰“åŒ…å˜é•¿åºåˆ—ã€‚
        _, (hidden, _) = self.lstm(packed)  # â‘¥ è·å–æœ€åä¸€å±‚éšè—çŠ¶æ€ã€‚
        logits = self.classifier(hidden[-1])  # â‘¦ ä½¿ç”¨æœ«å±‚éšè—æ€åˆ†ç±»ã€‚
        return logits
```

- å‰å‘ç»“æœå½¢çŠ¶ä¸º `[batch_size, num_classes]`ï¼ŒéŸ©ç«‹å³å¯åˆ¤æ–­å¼Ÿå­é€‚åˆå“ªé—¨åŠŸæ³•ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 3 å…¨è§£

```python
from torch.utils.data import Dataset

class BeastDataset(Dataset):
    def __init__(self, records):
        self.records = records  # â‘  ä¿å­˜çµå…½æ¡£æ¡ˆã€‚

    def __len__(self):
        return len(self.records)  # â‘¡ è¿”å›æ ·æœ¬æ•°é‡ã€‚

    def __getitem__(self, idx):
        entry = self.records[idx]
        image = load_image(entry["image_path"])  # â‘¢ è‡ªå®šä¹‰è¯»å–çµå…½ç”»åƒã€‚
        label = entry["label"]  # â‘£ å¯¹åº”å“é˜¶ã€‚
        return image, label
```

- æ­é… `DataLoader(..., num_workers=4, collate_fn=custom_collate)` å¯ç¨³å®šå¤„ç†å¼‚å½¢æ•°æ®ï¼Œå¦‚éŸ©ç«‹é©­ä½¿ä¼—å¤šå‚€å„¡ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 4 å…¨è§£

```python
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

model.eval()  # â‘  åˆ‡æ¢è¯„ä¼°æ¨¡å¼ã€‚
target_layers = [model.layer4[-1]]  # â‘¡ æŒ‡å®šæ³¨æ„åŠ›å±‚ã€‚
cam = GradCAM(model=model, target_layers=target_layers)  # â‘¢ æ„å»º Grad-CAMã€‚
grayscale_cam = cam(input_tensor=inputs)  # â‘£ ç”Ÿæˆçƒ­åŠ›å›¾ã€‚
overlay = show_cam_on_image(rgb_image, grayscale_cam[0], use_rgb=True)  # â‘¤ å°†æ³¨æ„åŠ›å åŠ åˆ°åŸå›¾ã€‚
```

- éŸ©ç«‹å¯å€Ÿæ­¤æ´å¯Ÿæ¨¡å‹å…³æ³¨çš„çµå…½éƒ¨ä½ï¼Œåˆ¤æ–­æ˜¯å¦èšç„¦äºå…³é”®æ³•çº¹ï¼Œå¦‚ä»–æ›¾è¾¨è¯†ä¸ƒç»é—¨æŠ¤å±±çµå…½å¼±ç‚¹ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 5 å…¨è§£

```python
import time

for batch_size in [32, 64, 128]:
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    start = time.perf_counter()  # â‘  è®°å½•èµ·å§‹æ—¶é—´ã€‚
    train_one_epoch(loader)
    duration = time.perf_counter() - start  # â‘¡ è®¡ç®—è€—æ—¶ã€‚
    val_loss = evaluate(val_loader)
    print(f"æ‰¹æ¬¡ {batch_size}: è€—æ—¶ {duration:.2f}s, éªŒè¯æŸå¤± {val_loss:.4f}")  # â‘¢ è¾“å‡ºæ¯”è¾ƒç»“æœã€‚
```

- è¾“å‡ºç±»ä¼¼ `æ‰¹æ¬¡ 64: è€—æ—¶ 12.45s, éªŒè¯æŸå¤± 0.8213`ï¼ŒéŸ©ç«‹å³å¯é€‰æ‹©æœ€åˆé€‚çš„æ‰¹æ¬¡è§„æ¨¡ã€‚

## å…ƒç¥æ¸¸å† Â· è¿ç§»å­¦ä¹ ä¸éƒ¨ç½²

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šåŠ è½½é¢„è®­ç»ƒ ResNet å¹¶å†»ç»“å¤§éƒ¨åˆ†å±‚ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šæ›¿æ¢å…¨è¿æ¥å±‚ä»¥é€‚é…æ–°çš„ç±»åˆ«æ•°ã€‚
3. ğŸ”¥ çªç ´ï¼šä½¿ç”¨ `torch.jit.trace` å¯¼å‡º TorchScript æ¨¡å‹ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šå°† TorchScript æ¨¡å‹æ¥å…¥ FastAPI æ¨ç†æœåŠ¡ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šè®¾è®¡å¥åº·æ£€æŸ¥ã€ç‰ˆæœ¬æ§åˆ¶ä¸æ€§èƒ½ç›‘æ§ã€‚

### é€é¢˜æ‹†è§£

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 1 å…¨è§£

```python
import torchvision.models as models
import torch.nn as nn

model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # â‘  åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚éŸ©ç«‹å€Ÿç”¨çµç•Œä¸Šå¤é˜µåŸºã€‚
for param in model.parameters():
    param.requires_grad = False  # â‘¡ å†»ç»“ä¸»å¹²å‚æ•°ï¼Œä¿ç•™åŸæœ‰æ³•åŠ›åº•è•´ã€‚
model.fc = nn.Linear(model.fc.in_features, num_classes)  # â‘¢ æ›¿æ¢é¡¶å±‚ä»¥é€‚é…æ–°ä»»åŠ¡ã€‚
```

- ä»…è®­ç»ƒæ–°å±‚å³å¯å¿«é€Ÿé€‚åº”çµå…½åˆ†ç±»ï¼ŒèŠ‚çœéŸ©ç«‹çš„çµçŸ³æ¶ˆè€—ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 2 å…¨è§£

```python
nn.init.kaiming_normal_(model.fc.weight)  # â‘  ä»¥å¼€æ˜åˆå§‹åŒ–æ¿€æ´»æ–°å±‚ï¼Œå¦‚éŸ©ç«‹ç‚¹ç‡ƒç„å¤©ç«ã€‚ 
model.fc.bias.data.zero_()  # â‘¡ åç½®æ¸…é›¶ï¼Œä¿æŒå¹³è¡¡ã€‚
```

- é€šè¿‡æ˜¾å¼åˆå§‹åŒ–ç¡®ä¿è®­ç»ƒåˆæœŸç¨³å®šï¼Œé¿å…åƒè½äº‘å®—å¤§æˆ˜æ—¶æ³•é˜µå¤±è¡¡ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 3 å…¨è§£

```python
import torch

example = torch.randn(1, 3, 224, 224)  # â‘  æ„é€ ç¤ºä¾‹è¾“å…¥ã€‚
traced = torch.jit.trace(model, example)  # â‘¡ è¿½è¸ªæ¨¡å‹è®¡ç®—å›¾ã€‚
traced.save("model.ts")  # â‘¢ ä¿å­˜æˆ TorchScript æ–‡ä»¶ã€‚
```

- è‹¥æ¨¡å‹å«æ¡ä»¶åˆ†æ”¯éœ€æ”¹ç”¨ `torch.jit.script`ï¼Œå¦åˆ™ä¼šé—æ¼åŠ¨æ€é€»è¾‘ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 4 å…¨è§£

```python
from fastapi import FastAPI
from fastapi.responses import Response
import torch
import pandas as pd

app = FastAPI(title="éŸ©ç«‹çµå…½é‰´å®šå°")
ts_model = torch.jit.load("model.ts")  # â‘  åŠ è½½è„šæœ¬æ¨¡å‹ã€‚
ts_model.eval()  # â‘¡ åˆ‡æ¢æ¨ç†æ¨¡å¼ã€‚

@app.post("/predict")
def predict(payload: dict):
    df = pd.DataFrame([payload])  # â‘¢ å°†è¯·æ±‚è½¬ä¸º DataFrameã€‚
    tensor = preprocess(df)  # â‘£ å¤ç”¨è®­ç»ƒæœŸé¢„å¤„ç†ã€‚
    with torch.no_grad():
        logits = ts_model(tensor)
        proba = logits.softmax(dim=1)  # â‘¤ è®¡ç®—æ¦‚ç‡åˆ†å¸ƒã€‚
    return {"probability": proba[0].tolist()}  # â‘¥ è¿”å›å¯ JSON åŒ–çš„åˆ—è¡¨ã€‚
```

- éŸ©ç«‹å¯åœ¨åŠå¸‚æ‘Šä½ä¸Šå®æ—¶é‰´å®šçµå…½æ½œåŠ›ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 5 å…¨è§£

```python
import time

@app.get("/healthz")
def healthz():
    start = time.perf_counter()
    try:
        _ = ts_model(torch.zeros(1, 3, 224, 224))  # â‘  è¿›è¡Œç©ºæ¨ç†ï¼Œç¡®ä¿æ¨¡å‹å­˜æ´»ã€‚
    except Exception as exc:
        return Response(status_code=503, content=f"å¼‚å¸¸: {exc}")
    latency = (time.perf_counter() - start) * 1000
    return {"status": "ok", "model_version": "v1.0", "latency_ms": round(latency, 2)}  # â‘¡ è¿”å›å¥åº·çŠ¶æ€ã€‚
```

- è¯¥å®ˆæŠ¤æ¥å£å¸®åŠ©éŸ©ç«‹éšæ—¶ç›‘æ§æœåŠ¡å»¶è¿Ÿï¼Œé˜²æ­¢åƒé€†æ˜Ÿç›Ÿçªè¢­æ—¶æªæ‰‹ä¸åŠã€‚

## é“æœå·©å›º Â· æŒç»­ç²¾è¿›

### é¢˜ç›®å›é¡¾
1. ğŸŒ± å…¥é—¨ï¼šé€‰æ‹©ä¸€ç¯‡è¿‘æœŸè®ºæ–‡æˆ–å®˜æ–¹æ•™ç¨‹è¿›è¡Œå¤ç°ã€‚
2. ğŸŒ¿ è¿›é˜¶ï¼šä½¿ç”¨ PyTorch Lightning / Accelerate é‡æ„è®­ç»ƒæµç¨‹ã€‚
3. ğŸ”¥ çªç ´ï¼šå°è¯•æ··åˆç²¾åº¦è®­ç»ƒæå‡æ•ˆç‡ã€‚
4. ğŸŒŸ åœ†æ»¡ï¼šç¼–å†™è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬ï¼ŒåŒ…å«æ‰“åŒ…ä¸ä¸Šçº¿æ­¥éª¤ã€‚
5. ğŸ›¡ï¸ åŒ–ç¥ï¼šè§„åˆ’ä¸‹ä¸€é˜¶æ®µè¿›é˜¶ä¸»é¢˜ï¼ˆNLPã€CVã€RL ç­‰ï¼‰ã€‚

### é€é¢˜æ‹†è§£

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 1 å…¨è§£

```python
from pathlib import Path
import json

plan = {
    "paper": "CutMix: Regularization Strategy to Train Strong Classifiers",  # â‘  é€‰å®šå¤ç°ç›®æ ‡ï¼ŒéŸ©ç«‹å¦‚åŒæŒ‘é€‰ä¸Šå¤åŠŸæ³•ã€‚
    "repo": "https://github.com/clovaai/CutMix-PyTorch",  # â‘¡ æ ‡è®°å®˜æ–¹ä»£ç ã€‚
    "checkpoints": [],
}

notes_dir = Path("hanli_research/notes")  # â‘¢ åˆ›å»ºè®°å½•ç›®å½•ã€‚
notes_dir.mkdir(parents=True, exist_ok=True)

for section in ["æ•°æ®é¢„å¤„ç†", "æ¨¡å‹ç»“æ„", "è®­ç»ƒè¶…å‚", "å®éªŒç»“æœ"]:  # â‘£ é€æ®µæ‹†è§£è®ºæ–‡ã€‚
    file = notes_dir / f"{section}.md"
    file.write_text(f"# {section}\néŸ©ç«‹å¤ç›˜ï¼š\n")  # â‘¤ å†™å…¥åˆå§‹ç¬”è®°ã€‚
    plan["checkpoints"].append(file.name)  # â‘¥ è®°å½•ç”Ÿæˆçš„æ–‡ä»¶ã€‚

Path("hanli_research/plan.json").write_text(json.dumps(plan, ensure_ascii=False, indent=2))  # â‘¦ è¾“å‡ºæ•´ä½“è®¡åˆ’ã€‚
```

- æ‰§è¡Œåä¼šç”Ÿæˆç¬”è®°æ–‡ä»¶ä¸ `plan.json`ï¼ŒéŸ©ç«‹å³å¯éšæ—¶å¤ç›˜ä¸åˆ†äº«ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 2 å…¨è§£

```python
import pytorch_lightning as pl
import torch.nn.functional as F

class HanLiClassifier(pl.LightningModule):
    def __init__(self, backbone):
        super().__init__()
        self.backbone = backbone  # â‘  æ³¨å…¥æ¨¡å‹éª¨æ¶ï¼Œä»¿ä½›éŸ©ç«‹è¯·å‚€å„¡åé•‡ã€‚

    def forward(self, x):
        return self.backbone(x)  # â‘¡ Lightning è‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼åŒæ­¥ã€‚

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)  # â‘¢ å‰å‘ä¼ æ’­ã€‚
        loss = F.cross_entropy(logits, y)  # â‘£ è®¡ç®—æŸå¤±ã€‚
        self.log("train_loss", loss, on_step=True, prog_bar=True)  # â‘¤ å®æ—¶è®°å½•ã€‚
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy(logits, y)
        self.log("val_loss", loss, prog_bar=True)  # â‘¥ éªŒè¯æŸå¤±ã€‚

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=1e-3)  # â‘¦ æŒ‡å®šä¼˜åŒ–å™¨ã€‚
```

- ç»“åˆ `Trainer(max_epochs=10)` å³å¯å¯åŠ¨è®­ç»ƒï¼ŒLightning è´Ÿè´£æ—¥å¿—ä¸å¤šå¡åŒæ­¥ï¼Œå®›å¦‚éŸ©ç«‹åé•‡å¤©æœºå ‚è°ƒåº¦è¯¸å³°å¼Ÿå­ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 3 å…¨è§£

```python
scaler = torch.cuda.amp.GradScaler()  # â‘  å‡†å¤‡æ··åˆç²¾åº¦ç¼©æ”¾å™¨ï¼Œå¦‚éŸ©ç«‹é©¾é©­æ¢µåœ£çœŸç«ã€‚
for epoch in range(epochs):
    for features, labels in train_loader:
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():  # â‘¡ åœ¨è‡ªåŠ¨æ··åˆç²¾åº¦ç¯å¢ƒè¿ç®—ã€‚
            logits = model(features)
            loss = criterion(logits, labels)
        scaler.scale(loss).backward()  # â‘¢ ç¼©æ”¾åå›ä¼ ã€‚
        scaler.step(optimizer)  # â‘£ æ›´æ–°å‚æ•°ã€‚
        scaler.update()  # â‘¤ è°ƒæ•´ç¼©æ”¾å› å­ï¼Œé˜²æ­¢æº¢å‡ºã€‚
```

- å€Ÿæ­¤éŸ©ç«‹å³å¯åœ¨çµç•Œå¤§æˆ˜ä¸­å…¼é¡¾é€Ÿåº¦ä¸ç¨³å®šæ€§ï¼Œå‡å°‘æ˜¾å­˜æ¶ˆè€—ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 4 å…¨è§£

```python
from subprocess import run

scripts = [
    ("lint", ["ruff", "check", "app"]),  # â‘  ä»£ç è§„çº¦ï¼Œå¦‚éŸ©ç«‹æ£€æŸ¥æ³•é˜µçº¹è·¯ã€‚
    ("tests", ["pytest", "-q"]),  # â‘¡ å•å…ƒè¯•ç‚¼ã€‚
    ("build", ["docker", "build", "-t", "hanli/vision:latest", "."]),  # â‘¢ æ„å»ºé•œåƒã€‚
    ("push", ["docker", "push", "hanli/vision:latest"]),  # â‘£ æ¨é€åˆ°çµç•Œä»“åº“ã€‚
]

for name, command in scripts:
    result = run(command, check=True)
    print(f"æ­¥éª¤ {name} å®Œæˆï¼Œè¿”å›ç  {result.returncode}")  # â‘¤ è¾“å‡ºæ¯æ­¥ç»“æœã€‚
```

- å¯ç»“åˆ CIï¼ˆå¦‚ GitHub Actionsï¼‰æ‰§è¡Œæ­¤è„šæœ¬ï¼Œå®ç°ä»æµ‹è¯•åˆ°éƒ¨ç½²çš„ä¸€æ¡é¾™æµç¨‹ã€‚

#### éŸ©ç«‹æ¼”ç»ƒï¼šé¢˜ 5 å…¨è§£

```python
roadmap = [
    {"quarter": "Q1", "focus": "NLP Transformer", "milestone": "å®Œæˆå°å‹ç¿»è¯‘æ¨¡å‹", "ally": "å°å¤©", "story": "é‡ç°ä¹±æ˜Ÿæµ·æ‹å–ä¼š"},  # â‘ 
    {"quarter": "Q2", "focus": "CV åŒ»ç–—å½±åƒ", "milestone": "æäº¤ Kaggle ç«èµ›", "ally": "å—å®«å©‰", "story": "è”æ‰‹ç‚¼åˆ¶è¾Ÿæ¯’ä¸¹"},
    {"quarter": "Q3", "focus": "RL", "milestone": "å¤ç° DQN åœ¨ä¿®ä»™å¡”", "ally": "å©´ç«¥é‡‘é˜™", "story": "æ“æ§å‚€å„¡å®ˆå«"},
]

for item in roadmap:
    print(f"å­£åº¦ {item['quarter']} Â· ä¸»é¢˜ {item['focus']} Â· ç›®æ ‡ {item['milestone']} Â· æ­æ¡£ {item['ally']} Â· å‰§æƒ… {item['story']}")  # â‘¡ è¾“å‡ºè§„åˆ’ã€‚
```

- è¿è¡Œåå°†æ‰“å°ä¸‰é˜¶æ®µè®¡åˆ’ï¼Œå¸®åŠ©éŸ©ç«‹åƒå¸ƒå±€å¤©æ¸ŠåŸå¤§æˆ˜é‚£æ ·æœªé›¨ç»¸ç¼ªï¼Œå¹¶å°†å­¦ä¹ ç›®æ ‡ä¸ã€Šå‡¡äººä¿®ä»™ä¼ ã€‹å‰§æƒ…ç›¸å‘¼åº”ã€‚
